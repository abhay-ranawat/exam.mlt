{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.datasets import make_classification, make_blobs\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Model\n",
    "\n",
    "$$\n",
    "y = sign(X W + b) \\\\\n",
    "$$\n",
    "$$\n",
    "J(W, b) = \\frac{1}{2} ||W||^2 + C \\sum_i  max\\left(0, 1 - y^i(W^T X^i + b)\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Soft SVM Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class softSVM:\n",
    "    def __init__(self, C):\n",
    "        self._support_vectors = None\n",
    "        self.C = C\n",
    "        self.w = None\n",
    "        self.b = None\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "\n",
    "        self.n = 0 # Number of data points\n",
    "        self.d = 0 # Number of dimensions\n",
    "\n",
    "    def __decision_function(self,  X):\n",
    "        return X.dot(self.w) + self.b\n",
    "\n",
    "    def __cost(self, margin):\n",
    "        return (1/2) * self.w.dot(self.w) + self.C * np.sum(np.maximum(0, 1 - margin))\n",
    "\n",
    "    def __margin(self, X, y):\n",
    "        return y * self.__decision_function(X)\n",
    "\n",
    "    def fit(self, X, y, lr=1e-3, epochs=500):\n",
    "        #Initialise w and b\n",
    "        self.n, self.d = X.shape\n",
    "        self.w = np.random.randn(self.d)\n",
    "        self.b = 0\n",
    "\n",
    "        #Required only for plotting \n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "        losses = []\n",
    "\n",
    "        for _ in range(epochs):\n",
    "            margin = self.__margin(X, y)\n",
    "            loss = self.__cost(margin)\n",
    "            losses.append(loss)\n",
    "\n",
    "            misclassified_pts_idx = np.where(margin < 1)[0]\n",
    "            dJdw = self.w - self.C * y[misclassified_pts_idx].dot(X[misclassified_pts_idx])\n",
    "            self.w -= lr * dJdw\n",
    "\n",
    "            dJdb = -1 * self.C * np.sum(y[misclassified_pts_idx])\n",
    "            self.b -= lr * dJdb\n",
    "\n",
    "        self._support_vectors = np.where(self.__margin(X, y) <= 1.0)[0] \n",
    "        \n",
    "    def predict(self, X):\n",
    "        return np.sign(self.__decision_function(X))\n",
    "\n",
    "    def score(self, X, y):\n",
    "        pred = self.predict(x)\n",
    "        return np.mean(y==pred)\n",
    "\n",
    "    def plot_decision_boundary(self):\n",
    "        plt.figure(figsize=(8,8))\n",
    "        plt.scatter(self.X[:,0], self.X[:, 1], c = self.y, marker = 'o', s = 100, cmap = 'autumn')\n",
    "        ax = plt.gca()\n",
    "        xlim = ax.get_xlim()\n",
    "        ylim = ax.get_ylim()\n",
    "\n",
    "        # Create a grid to evaluate the model\n",
    "        xx = np.linspace(xlim[0], xlim[1], 30)\n",
    "        yy = np.linspace(ylim[0], ylim[1], 30)\n",
    "        YY, XX = np.meshgrid(yy, xx)\n",
    "        xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
    "        Z = self.__decision_function(xy).reshape(XX.shape)\n",
    "\n",
    "        ## Plot decision boundary and margins\n",
    "        ax.contour(XX, YY, Z, colors=['g', 'k', 'g'], levels = [-1, 0, 1],\n",
    "                    linestyles = ['--', '-', '--'], linewidths = [2.0, 2.0, 2.0])\n",
    "\n",
    "        # Highlight the support vectors\n",
    "        ax.scatter(self.X[:, 0][self._support_vectors],\n",
    "                    self.X[:, 1][self._support_vectors], s =250,\n",
    "                    linewidth = 1, facecolors='none', edgecolors='k')\n",
    "\n",
    "        plt.xlabel('x1')\n",
    "        plt.ylabel('x2')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo 1: Linearly seperable data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = make_blobs(n_samples = 60,\n",
    "                    n_features = 2,\n",
    "                    centers = [[0,0],[6,6]],\n",
    "                    cluster_std = 1,\n",
    "                    random_state = 12)\n",
    "\n",
    "Y = np.where(Y == 0, -1, 1)\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], marker='o', c=Y, s=200, edgecolor='k', cmap='autumn')\n",
    "plt.xlabel('x1', fontsize = 20)\n",
    "plt.ylabel('x2', fontsize = 20)\n",
    "plt.title('Data points', fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = softSVM(C = 1)\n",
    "svm.fit(X, Y)\n",
    "\n",
    "print(svm.w)\n",
    "\n",
    "def get_hyperplane_value(x, w, b, offset):\n",
    "    return -1 * (w[0] * x + b + offset) / w[1]\n",
    "\n",
    "svm.plot_decision_boundary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo 2: Linearly seperable with noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_blobs(n_samples=100,\n",
    "                    centers = 2,\n",
    "                    random_state=0,\n",
    "                    cluster_std=1.1)\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], marker='o', c=y, s=200, edgecolor='k', cmap='autumn')\n",
    "plt.xlabel('x1', fontsize = 20)\n",
    "plt.ylabel('x2', fontsize = 20)\n",
    "plt.title('Data points', fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[ y == 0] = -1 \n",
    "svm = softSVM(C=10)\n",
    "svm.fit(X, y)\n",
    "print(svm.w, svm.b)\n",
    "\n",
    "svm.plot_decision_boundary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = softSVM(C=100)\n",
    "svm.fit(X, y)\n",
    "print(svm.w, svm.b)\n",
    "\n",
    "svm.plot_decision_boundary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_circles\n",
    "X, y = make_circles(500, factor=0.5, noise = 0.08)\n",
    "y[y == 0] = -1\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.scatter(X[:, 0], X[:, 1], marker='o', c = y, s =200, edgecolors='k', cmap='autumn')\n",
    "plt.xlabel('x1', fontsize=20)\n",
    "plt.ylabel('x2', fontsize=20)\n",
    "plt.title('Data points', fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[y == 0] = -1\n",
    "svm = softSVM(C = 10)\n",
    "svm.fit(X, y)\n",
    "\n",
    "fig = plt.figure(figsize = (8,8))\n",
    "svm.plot_decision_boundary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly linear SVM is not able to handle this. We need Kernel methods,."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be implementing dual problem of soft SVM by replacing the dot product between two feature vectors with the kernel function. \n",
    "\n",
    "The dual for soft SVM is as follows:\n",
    "$$\n",
    "\\begin{align}\n",
    "L_d(\\alpha) &= \\sum_{i=1}^n \\alpha^{(i)} - \\frac{1}{2} \\sum_{i=1}^n \\sum_{k=1}^n \\alpha^{(i)} \\alpha^{(k)} y^{(i)} y^{(k)} x^{(i)^T} x^{(k)} \\\\\n",
    "\n",
    "            &= \\sum_{i=1}^n \\alpha^{(i)} - \\frac{1}{2} \\sum_{i=1}^n \\sum_{k=1}^n \\langle \\alpha^{(i)} y^{(i)} x^{(i)} , \\alpha^{(k)}  y^{(k)}  x^{(k)} \\rangle\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "It is a concave problem that is maximised using a solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVMDualProblem:\n",
    "    def __init__(self, C=1.0, kernel ='rbf', sigma=0.1, degree=2):\n",
    "        self.C = C\n",
    "        if kernel == 'poly':\n",
    "            self.kernel = self._polynomial_kernel\n",
    "            self.c = 1\n",
    "            self.degree = degree\n",
    "\n",
    "        else:\n",
    "            self.kernel = self._rbf_kernel\n",
    "            self.sigma = sigma\n",
    "\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        self.alpha = None\n",
    "        self.b = 0\n",
    "        self.ones = None\n",
    "\n",
    "    def _rbf_kernel(self, X1, X2):\n",
    "        return np.exp(-(1/self.sigma **2) * np.linalg.norm(X1[:, np.newaxis] - X2[np.newaxis, :]), axis = 2)\n",
    "\n",
    "    def _polynomial_kernel(self, X1, X2):\n",
    "        return (self.c + X1.dot(X2.T)) ** self.degree\n",
    "\n",
    "    def fit(self, X, y, lr = 1e-3, epochs=100):\n",
    "        self.X = X\n",
    "        self. y = y\n",
    "\n",
    "        self.alpha = np.random.random(X.shape[0])\n",
    "        self.b = 0\n",
    "        self.ones = np.ones(X.shape[0])\n",
    "\n",
    "        y_iy_jk_ij = np.outer(y, y) * self.kernel(X, X)\n",
    "\n",
    "        losses = []\n",
    "\n",
    "        for _ in range(epochs):\n",
    "            gradient = self.ones - y_iy_jk_ij.dot(self.alpha)\n",
    "\n",
    "            self.alpha = self.alpha + lr * gradient\n",
    "\n",
    "            self.alpha[self.alpha > self.C] = self.C\n",
    "            self.alpha[self.alpha < 0] = 0\n",
    "\n",
    "            loss = np.sum(self.alpha) - 0.5 * np.sum(np.outer(self.alpha, self.alpha) * y_iy_jk_ij) \n",
    "            losses.append(loss)\n",
    "\n",
    "        index = np.where((self.alpha > 0) & (self.alpha < self.C))[0]\n",
    "        b_i = y[index] - (self.alpha * y).dot(self.kernel(X, X[index]))\n",
    "        self.b = np.mean(b_i)\n",
    "\n",
    "        plt.plot(losses)\n",
    "        plt.title(\"loss per epochs\")\n",
    "        plt.show()\n",
    "\n",
    "    def _decision_function(self, X):\n",
    "        return (self.alpha * self.y).dot(self.kernel(self.X, X)) + self.b\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.sign(self._decision_function(X))\n",
    "\n",
    "    def score(self, X, y):\n",
    "        y_hat = self.predict(X)\n",
    "        return np.mean(y == y_hat)\n",
    "\n",
    "    def plot_decision_boundary(self):\n",
    "        plt.scatter(self.X[:, 0], self.X[:, 1], c = self.y, s = 50, cmap = plt.cm.Paired, alpha = 0.5)\n",
    "        ax = plt.gca()\n",
    "        xlim = ax.get_xlim()\n",
    "        ylim = ax.get_ylim()\n",
    "\n",
    "        xx = np.linspace(xlim[0], xlim[1], 30)\n",
    "        yy = np.linspace(ylim[0], ylim[1], 30)\n",
    "        YY, XX = np.meshgrid(yy, xx)\n",
    "        xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
    "        Z = self._decision_function(xy).reshape(XX.shape)\n",
    "\n",
    "        ax.contour(XX, YY, Z, colors=['b', 'g', 'r'], levels =[-1, 0, 1], alpha = 0.5,\n",
    "                    linestyles=['--', '-', '--'], linewidths = [2.0, 2.0, 2.0])\n",
    "\n",
    "        ax.scatter(self.X[:, 0][self.alpha > 0.],\n",
    "                    self.X[:, 1][self.alpha > 0.], s =50,\n",
    "                    linewidth = 1, facecolors='none', edgecolors='k')\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVMDualProblem(C = 1.0, kernel='poly', degree=2)\n",
    "svm.fit(X, y, lr = 1e-3)\n",
    "print(\"train score:\", svm.score(X, y))\n",
    "svm.plot_decision_boundary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
