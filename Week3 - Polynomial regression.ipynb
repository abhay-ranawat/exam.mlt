{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polynomial Regression\n",
    "\n",
    "`Features --> Polynomial tranformation --> Linear regression --> Label`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LinReg Class implemented earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinReg(object):\n",
    "    '''\n",
    "    Linear regression Model\n",
    "    ------------------------------------\n",
    "    y = X@w\n",
    "    X: A feature matrix\n",
    "    w: weight vector\n",
    "    y; Label Vector\n",
    "    '''\n",
    "\n",
    "    def __init__(self):\n",
    "        self.t0 = 200\n",
    "        self.t1 = 100000\n",
    "\n",
    "    def predict(self, X:np.ndarray) -> np.ndarray:\n",
    "        ''' Prediction of ouotput label for a given input\n",
    "\n",
    "            Args:\n",
    "                X: Feature matrix of shape (n, m+1).\n",
    "                w: weight vector of shape (m+1,)\n",
    "\n",
    "            Returns:\n",
    "                y: Predicted label vector of shape (n,) \n",
    "\n",
    "        '''\n",
    "\n",
    "        y = X @ self.w\n",
    "        return y\n",
    "\n",
    "    def loss(self, X: np.ndarray, y: np.ndarray) -> float:\n",
    "        '''Calculates loss for a model based on known labels\n",
    "    \n",
    "        Args:\n",
    "            X: Feature matrix for given inputs\n",
    "            y: Output label vector as predicted by the given model\n",
    "            w: Weight vector\n",
    "\n",
    "        Returns:\n",
    "            Loss\n",
    "        '''\n",
    "\n",
    "        err = self.predict(X) - y\n",
    "        return (1/2)*(np.transpose(err) @ err)\n",
    "\n",
    "    def rmse(self, X: np.ndarray, y: np.ndarray) -> float:\n",
    "        '''Calculate root mean square error of prediction wrt actual label.\n",
    "        \n",
    "        Args:\n",
    "            X: Feature matrix for the given inputs\n",
    "            y: output label vector as predicted by the given model\n",
    "\n",
    "        Returns:\n",
    "            Loss\n",
    "        '''\n",
    "\n",
    "        return np.sqrt((2/X.shape[0]) * self.loss(X, y))\n",
    "\n",
    "    def fit(self, X:np.ndarray, y:np.ndarray) -> float:\n",
    "        '''Estimates parameters of the linear regression model with normal equation.\n",
    "    \n",
    "        Args: \n",
    "            X: Feature matrix for given inputs.\n",
    "            y: Actual label vector.\n",
    "\n",
    "        Returns:\n",
    "            Weight vector\n",
    "        '''\n",
    "        self.w = np.linalg.pinv(X) @ y \n",
    "        return self.w\n",
    "\n",
    "    def calculate_gradient(self, X:np.ndarray, y:np.ndarray) -> np.ndarray:\n",
    "        '''Calculates gradients of loss dunction wrt weight vector on training set\n",
    "    \n",
    "        Arguments:\n",
    "\n",
    "            X: Feature matrix for training data.\n",
    "            y: Label vector for training data\n",
    "            w: Weight vector\n",
    "\n",
    "        Returns:\n",
    "            A vector of gradients.\n",
    "        '''\n",
    "\n",
    "        return np.transpose(X) @ (self.predict(X) - y)\n",
    "    \n",
    "    def update_weights(self, grad: np.ndarray, lr: float) -> np.ndarray:\n",
    "        '''\n",
    "        Updates the weights based on the gradient of loss function.\n",
    "\n",
    "        Weight updates are carried out with the fiollowing formula:\n",
    "            w_new := w_old - lr * grad\n",
    "\n",
    "        Args:\n",
    "            1. w: Weight vector\n",
    "            2. grad: gradient of loss w.r.t w\n",
    "            3. lr: learning rate\n",
    "\n",
    "        Returns:\n",
    "            Updated weight vector\n",
    "        '''\n",
    "\n",
    "        return (self.w - lr*grad)\n",
    "\n",
    "    def learning_schedule(self, t) -> float:\n",
    "        lr = (self.t0) / (t + self.t1)\n",
    "        return lr\n",
    "\n",
    "    def gd(self, X:np.ndarray, y:np.ndarray, num_epochs:int, lr:float) -> np.ndarray:\n",
    "        '''Estimates parameters of linear regression model through gradient descent.\n",
    "    \n",
    "        Arguments:\n",
    "            X: Feature matrix for training data\n",
    "            y: Label vector for training data\n",
    "            lr: learning rate\n",
    "            num_epochs: Number of training steps\n",
    "\n",
    "        Returns:\n",
    "            Weight vector: Final weight vector\n",
    "            Error vector across different iterations\n",
    "            Weight vectors acrss different iterations\n",
    "        '''\n",
    "        self.w = np.zeros((X.shape[1])) # parameter vector initialised to zero\n",
    "        self.w_all = [] #all paramenter across iterations\n",
    "        self.err_all = [] # all arrors across iterations\n",
    "\n",
    "\n",
    "\n",
    "        #Gradient descent loop\n",
    "        for i in np.arange(0, num_epochs):\n",
    "\n",
    "            #Gradient Calulation\n",
    "            dJdW = self.calculate_gradient(X, y)\n",
    "\n",
    "            self.w_all.append(self.w)\n",
    "\n",
    "            #calculate arror due to the current weight vector:\n",
    "            self.err_all.append(self.loss(X, y))\n",
    "\n",
    "            #Weight vector update.\n",
    "            self.w = self.update_weights(dJdW, lr)\n",
    "\n",
    "        return self.w\n",
    "    \n",
    "    def mbgd(self, X: np.ndarray, y: np.ndarray, num_epochs: int, batch_size: int) -> np.ndarray:\n",
    "\n",
    "        '''Estimates parametrs of linear regression model through gradient descent.\n",
    "    \n",
    "        Args:\n",
    "            1. X: Feature matrix for training data.\n",
    "            2. y: Label vector for training data.\n",
    "            3. num_iters: Number of iterations.\n",
    "\n",
    "        Returns:\n",
    "            Weight vector: Final weight vector\n",
    "            Error vector across different iterations\n",
    "         Weight vector acosss different iterations\n",
    "        \n",
    "        '''\n",
    "        # Parameter vector initialised to [0,0]\n",
    "        self.w = np.zeros((X.shape[1]))\n",
    "        \n",
    "        self.w_all = [] # all parameters across iterations.\n",
    "        self.err_all = [] # error across iterations\n",
    "\n",
    "        mini_batch_id = 0\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            shuffled_indices = np.random.permutation(X.shape[0])\n",
    "            X_shuffled = X[shuffled_indices]\n",
    "            y_shuffled = y[shuffled_indices]\n",
    "\n",
    "            for i in range(0, X.shape[0], batch_size):\n",
    "                mini_batch_id += 1\n",
    "                xi = X_shuffled[i: i + batch_size]\n",
    "                yi = y_shuffled[i: i + batch_size]\n",
    "            \n",
    "                self.w_all.append(self.w)\n",
    "                self.err_all.append(self.loss(xi, yi))\n",
    "\n",
    "                dJdW = 2/batch_size * self.calculate_gradient(xi, yi)\n",
    "\n",
    "                self.w = self.update_weights(dJdW, self.learning_schedule(mini_batch_id))\n",
    "            \n",
    "        return self.w\n",
    "    \n",
    "    def sgd(self, X: np.ndarray, y: np.ndarray, num_epochs: int) -> np.ndarray:\n",
    "\n",
    "        '''Estimates parametrs of linear regression model through stochastic gradient descent.\n",
    "    \n",
    "        Args:\n",
    "            1. X: Feature matrix for training data.\n",
    "            2. y: Label vector for training data.\n",
    "            3. num_epochs: Number of epochs.\n",
    "\n",
    "        Returns:\n",
    "            Weight vector: Final weight vector\n",
    "            Error vector across different iterations\n",
    "            Weight vector acosss different iterations\n",
    "        '''\n",
    "\n",
    "        self.w_all = [] # all parameters across iterations.\n",
    "        self.err_all = [] # error across iterations\n",
    "\n",
    "        # Parameter vector initialised to [0,0]\n",
    "        self.w = np.zeros((X.shape[1]))\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            for i in range(X.shape[0]):\n",
    "                random_index = np.random.randint(X.shape[0])\n",
    "                xi = X[random_index: random_index + 1]\n",
    "                yi = y[random_index: random_index + 1]\n",
    "            \n",
    "                self. err_all.append(self.loss(xi, yi))\n",
    "                self.w_all.append(self.w)\n",
    "\n",
    "                gradients = 2 * self.calculate_gradient(xi, yi)\n",
    "                lr = self.learning_schedule(epoch * X.shape[0] + i)\n",
    "\n",
    "                self.w = self.update_weights(gradients, lr)\n",
    "            \n",
    "\n",
    "        return self.w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial Transformation\n",
    "\n",
    "Steps for generating polynomial transformation of degree $M$\n",
    "\n",
    "1. Generate combination of input features of lengths $= 0, 1,...., M$.\n",
    "2. Perform multiplication operation between features to obtain the new features.\n",
    "\n",
    "For eg:\n",
    "* For a single feature $x_1$, $\\phi_m = [1, x_1^1, x_1^2,....,x_1^m]$\n",
    "    * Generate combinations of $\\{1, x_1, (x_1, x_1), (x_1, x_1, x_1),....,(x_1, x_1,.....)\\}$\n",
    "    * TRaking the product of elements in each combination: \n",
    "    $$\\phi_m(x_1) = \\{1, x_1, x_1^2,.....,x_1^m\\}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import functools\n",
    "\n",
    "def get_combinations(x, degree):\n",
    "    return itertools.combinations_with_replacement(x, degree)\n",
    "\n",
    "def compute_new_features(items):\n",
    "    #reduce(lambda x, y: x * y, items, [1,2,3,4,5]) calculates ((((1*2)*3)*4)*5)\n",
    "    return functools.reduce(lambda x, y: x * y, items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{items: compute_new_features(items) for items in get_combinations([1], 3)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{items: compute_new_features(items) for items in get_combinations([2,3], 3)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{items: compute_new_features(items) for items in get_combinations([1, 4], 4)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polynomial_transform(x, degree, logging=False):\n",
    "    # Converts to feature matrix.\n",
    "    if x.ndim == 1:\n",
    "        x = x[:, None]\n",
    "\n",
    "    x_t = x.transpose() #transposes the feature matrix\n",
    "    features = [np.ones(len(x))] # populates 1s as the first features\n",
    "\n",
    "    if logging:\n",
    "        print (\"Input:\", x)\n",
    "    \n",
    "    for degree in range(1, degree+1):\n",
    "        for items in get_combinations(x_t, degree):\n",
    "            features.append(compute_new_features(items))\n",
    "            if logging:\n",
    "                print (items, \":\", compute_new_features(items))\n",
    "\n",
    "    if logging:\n",
    "        print(np.asarray(features).transpose())\n",
    "\n",
    "    return np.asarray(features).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polynomial_transform(np.array([2]), 3, logging=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polynomial_transform(np.array([2, 3]), 2, logging=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polynomial_transform(np.array([[2, 3], [4,5]]), 2, logging=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polynomial_transform(np.array([[2, 3], [4,5]]), 3, logging=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polynomial_transform(np.array([2]), 0, logging=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non_Linear training data generation\n",
    "\n",
    "We generate training data with a single feature $x_1$ and label $y = sin(2 \\pi x_1) + noise$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_nonlin_training_set(func, sample_size, std):\n",
    "    x = np.linspace(0, 1, sample_size)\n",
    "    y = func(x) + np.random.normal(scale=std, size = x.shape)\n",
    "\n",
    "    return x, y\n",
    "\n",
    "def nonlin(x):\n",
    "    return np.sin(2 * np.pi * x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_training_data(X_train, y_train):\n",
    "    points = np.linspace(0, 1, 100)\n",
    "    output = nonlin(points)\n",
    "\n",
    "    plt.scatter(X_train, y_train, facecolor=\"none\", edgecolors=\"b\", s= 50, label='training data')\n",
    "    plt.plot(points, output, c='g', label=\"$\\sin(2\\pi x)$\")\n",
    "    plt.xlabel('$x_1$')\n",
    "    plt.ylabel('y')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def visualise_model_fit(X, y, lin_reg, degree):\n",
    "    '''plots trained model along with the data genration function'''\n",
    "\n",
    "    points = np.linspace(0, 1, 100)\n",
    "    output = nonlin(points)\n",
    "\n",
    "    if degree > 0:\n",
    "        plt.scatter(X, y, facecolor=\"none\", edgecolors=\"b\", s =50, label ='training data')\n",
    "\n",
    "    plt.plot(points, output, c=\"g\", label = \"$\\sin(2\\pi x)$\")\n",
    "\n",
    "    y_hat = lin_reg.predict(polynomial_transform(points, degree))\n",
    "    plt.plot(points, y_hat, c=\"r\", label=\"$h_\\mathbf{w}(x)$\") \n",
    "    plt.xlabel('$x_1$')\n",
    "    plt.ylabel('y')\n",
    "    plt.ylim(-1.5, 1.5)\n",
    "    plt.title(\"M={}\".format(degree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 10\n",
    "X, y = create_nonlin_training_set(nonlin, num_samples, 0.2)\n",
    "visualize_training_data(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial model\n",
    "\n",
    "Let's train a polynomial model on this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree = 9\n",
    "X_transform = polynomial_transform(X, degree)\n",
    "lin_reg = LinReg()\n",
    "lin_reg.fit(X_transform, y)\n",
    "visualise_model_fit(X, y, lin_reg, degree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train multiplle polynomial regression models with different degree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(12, 8))\n",
    "sns.set_context(\"notebook\", font_scale=1.5, rc={\"lines.linewidth\": 2.5})\n",
    "\n",
    "for i, degree in enumerate([0,1,3,5,7,9]):\n",
    "    plt.subplot(3, 3, i+1)\n",
    "    X_transform = polynomial_transform(X, degree)\n",
    "    lin_reg = LinReg()\n",
    "    lin_reg.fit(X_transform, y)\n",
    "    visualise_model_fit(X, y, lin_reg, degree)\n",
    "\n",
    "f.tight_layout()\n",
    "plt.legend(bbox_to_anchor=(1.05, 0.64), loc=2, borderaxespad=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Selection\n",
    "\n",
    "* One polynomial model per degree. Which one to select?\n",
    "* Process\n",
    "    * Fix the list of degrees you want to experiment with.\n",
    "    * Divide the training data into training, validation and test.\n",
    "    * For each degree $m$:\n",
    "        * Train polynomial regression model with training data\n",
    "        * Calculate training and validation errors on the trained model\n",
    "    * Select the model with the lowest training and validation loss among all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def convert_dict_to_df(w_dict, degree):\n",
    "    poly_w_dict = {i: np.array(np.zeros(degree)) for i in range(degree)}\n",
    "    for deg in poly_w_dict:\n",
    "        weight_vec = w_dict[deg]\n",
    "        for i in range(len(weight_vec)):\n",
    "            poly_w_dict[deg][i] = weight_vec[i]\n",
    "    \n",
    "    poly_w_df = pd.DataFrame(poly_w_dict)\n",
    "    poly_w_df.columns = ['w_' + str(i) for i in range(degree)]\n",
    "    return poly_w_df\n",
    "\n",
    "def plot_model_selection(training_errors, val_errors):\n",
    "    plt.plot(training_errors, 'o-', mfc=\"none\", mec=\"b\", ms = \"10\", c=\"b\", label = \"Training error\")\n",
    "    plt.plot(val_errors, 'o-', mfc=\"none\", mec=\"r\", ms = \"10\", c=\"r\", label=\"Validation error\" )\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"degree\")\n",
    "    plt.xlabel('RMSE')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_errors = []\n",
    "val_errors = []\n",
    "w_dict = {}\n",
    "\n",
    "X_val = np.linspace(0, 1, 100)\n",
    "y_val = nonlin(X_val)\n",
    "\n",
    "for i in range(10):\n",
    "    X_transform = polynomial_transform(X, i)\n",
    "    X_val_transform = polynomial_transform(X_val, i)\n",
    "\n",
    "    lin_reg = LinReg()\n",
    "    lin_reg.fit(X_transform, y)\n",
    "\n",
    "    w_dict[i] = lin_reg.w\n",
    "    training_errors.append(lin_reg.rmse(X_transform, y))\n",
    "    val_errors.append(lin_reg.rmse(X_val_transform, y_val + np.random.normal(scale=0.25, size=len(y_val))))\n",
    "\n",
    "plot_model_selection(training_errors, val_errors)\n",
    "convert_dict_to_df(w_dict, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "\n",
    "* Higher order polynomial terms are assigned larger weights. The larger weights are problematic as a small change in the input causes a large change in the input.\n",
    "\n",
    "\n",
    "Let's try increasing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 100000\n",
    "X, y = create_nonlin_training_set(nonlin, num_samples, 0.2)\n",
    "visualize_training_data(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree = 9\n",
    "X_transform = polynomial_transform(X, degree)\n",
    "lin_reg = LinReg()\n",
    "lin_reg.fit(X_transform, y)\n",
    "visualise_model_fit(X, y, lin_reg, degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(12, 8))\n",
    "sns.set_context(\"notebook\", font_scale=1.5, rc={\"lines.linewidth\": 2.5})\n",
    "\n",
    "for i, degree in enumerate([0,1,3,5,7,9]):\n",
    "    plt.subplot(3, 3, i+1)\n",
    "    X_transform = polynomial_transform(X, degree)\n",
    "    lin_reg = LinReg()\n",
    "    lin_reg.fit(X_transform, y)\n",
    "    visualise_model_fit(X, y, lin_reg, degree)\n",
    "\n",
    "f.tight_layout()\n",
    "plt.legend(bbox_to_anchor=(1.05, 0.64), loc=2, borderaxespad=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_errors = []\n",
    "val_errors = []\n",
    "w_dict = {}\n",
    "\n",
    "X_val = np.linspace(0, 1, 100)\n",
    "y_val = nonlin(X_val)\n",
    "\n",
    "for i in range(10):\n",
    "    X_transform = polynomial_transform(X, i)\n",
    "    X_val_transform = polynomial_transform(X_val, i)\n",
    "\n",
    "    lin_reg = LinReg()\n",
    "    lin_reg.fit(X_transform, y)\n",
    "\n",
    "    w_dict[i] = lin_reg.w\n",
    "    training_errors.append(lin_reg.rmse(X_transform, y))\n",
    "    val_errors.append(lin_reg.rmse(X_val_transform, y_val + np.random.normal(scale=0.25, size=len(y_val))))\n",
    "\n",
    "plot_model_selection(training_errors, val_errors)\n",
    "convert_dict_to_df(w_dict, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
